{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import mido\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lakh_midi_dir = Path(\"../data/lmd_full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "torch.random.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "TARGET_TICKS_PER_BEAT = 4\n",
    "WINDOW_HALF_TICKS = 256\n",
    "INSTRUMENT_OVERTONES = True\n",
    "SEPARATE_DRUMS = True\n",
    "PATCH_NORMALIZE = True\n",
    "PAD_PIANO_ROLL = False # For handling boundary patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKERS = json.load(open(\"../data/markers_qn.json\"))\n",
    "\n",
    "def parse_midi(file_path):\n",
    "    \"\"\"\n",
    "    Parse a MIDI file into a list of bar segments per track.\n",
    "    A bar segment is defined as a list of MIDI messages encoded as tuples that fit into a single bar.\n",
    "    A tuple is defined as (time, note, velocity, duration, channel, program)\n",
    "    \"\"\"\n",
    "    midi = mido.MidiFile(file_path, clip=True)\n",
    "\n",
    "    track_data = {\n",
    "        (track.name if track.name else f\"track_{idx}\"): []\n",
    "        for idx, track in enumerate(midi.tracks)\n",
    "    }\n",
    "\n",
    "    file_name = os.path.basename(file_path).split('.mid')[0]\n",
    "    marker_qns = MARKERS[file_name]\n",
    "    markers_ticks = [int(round(x[0] * midi.ticks_per_beat)) for x in marker_qns]\n",
    "\n",
    "    channel_volumes = {\n",
    "        i: 127\n",
    "        for i in range(16)\n",
    "    }\n",
    "    channel_expressions = {\n",
    "        i: 127\n",
    "        for i in range(16)\n",
    "    }\n",
    "    channel_instruments = {\n",
    "        i: 0\n",
    "        for i in range(16)\n",
    "    }\n",
    "\n",
    "    for idx, track in enumerate(midi.tracks):\n",
    "        track_name = track.name if track.name else f\"track_{idx}\"\n",
    "        current_ticks = 0\n",
    "        for msg in track:\n",
    "            current_ticks += msg.time\n",
    "            if msg.type == \"control_change\":\n",
    "                if msg.control == 7:\n",
    "                    channel_volumes[msg.channel] = msg.value\n",
    "                elif msg.control == 11:\n",
    "                    channel_expressions[msg.channel] = msg.value\n",
    "            elif msg.type == \"program_change\":\n",
    "                channel_instruments[msg.channel] = msg.program\n",
    "            elif msg.type == \"marker\":\n",
    "                pass\n",
    "            elif msg.type == \"note_on\" and msg.velocity > 0:\n",
    "                velocity = msg.velocity * (channel_volumes[msg.channel] / 127.) * (\n",
    "                            channel_expressions[msg.channel] / 127.)\n",
    "                program = channel_instruments[msg.channel]\n",
    "                track_data[track_name].append({\n",
    "                    \"time\": current_ticks,\n",
    "                    \"note\": msg.note,\n",
    "                    \"velocity\": velocity,\n",
    "                    \"duration\": -1,\n",
    "                    \"channel\": msg.channel,\n",
    "                    \"program\": program\n",
    "                })\n",
    "            elif msg.type == \"note_off\" or (msg.type == \"note_on\" and msg.velocity == 0):\n",
    "                for note in track_data[track_name]:\n",
    "                    if note[\"duration\"] == -1 and note[\"note\"] == msg.note and note[\"channel\"] == msg.channel:\n",
    "                        note[\"duration\"] = current_ticks - note[\"time\"]\n",
    "                        break\n",
    "\n",
    "    # Remove duplicate marker ticks\n",
    "    markers_ticks = list(set(markers_ticks))\n",
    "    markers_ticks.sort()\n",
    "\n",
    "    return track_data, markers_ticks, midi.ticks_per_beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def instrument_overtone_intensities(program, num_harmonics=3, max_harmonic=5):\n",
    "    \"\"\"\n",
    "    Generate a set of harmonics and their intensities for a given instrument program.\n",
    "    The harmonics are random but fixed for a given program.\n",
    "    \"\"\"\n",
    "    np.random.seed(hash(str(program)) % 2**32)\n",
    "\n",
    "    harmonics = np.sort(np.random.choice(max_harmonic, num_harmonics, replace=False) + 2)\n",
    "    intensities = np.sort(np.random.rand(num_harmonics))[::-1]\n",
    "\n",
    "    # Return to original seed\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    return harmonics, intensities\n",
    "\n",
    "instrument_categories = {\n",
    "    \"Piano\": range(0, 8), \"Chromatic Percussion\": range(8, 16),\n",
    "    \"Organ\": range(16, 24), \"Guitar\": range(24, 32),\n",
    "    \"Bass\": range(32, 40), \"Strings\": range(40, 48),\n",
    "    \"Ensemble\": range(48, 56), \"Brass\": range(56, 64),\n",
    "    \"Reed\": range(64, 72), \"Pipe\": range(72, 80),\n",
    "    \"Synth Lead\": range(80, 88), \"Synth Pad\": range(88, 96),\n",
    "    \"Synth Effects\": range(96, 104), \"Ethnic\": range(104, 112),\n",
    "    \"Percussive\": range(112, 120), \"Sound Effects\": range(120, 128)\n",
    "}\n",
    "\n",
    "def hz_to_midi(frequency):\n",
    "    if frequency <= 0:\n",
    "        raise ValueError(\"Frequency must be greater than 0 Hz.\")\n",
    "    return 69 + 12 * np.log2(frequency / 440.0)\n",
    "\n",
    "def midi_to_hz(midi_note):\n",
    "    return 440.0 * 2**((midi_note - 69) / 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_piano_roll(\n",
    "    note_data,\n",
    "    ticks_per_beat,\n",
    "    chroma=False,\n",
    "    target_ticks_per_beat=24,\n",
    "    instrument_overtones=False,\n",
    "    separate_drums=False\n",
    "):\n",
    "    if len(note_data) == 0:\n",
    "        return None\n",
    "    num_notes = 12 if chroma else 128\n",
    "    duration_ticks = note_data[-1][\"time\"] + note_data[-1][\"duration\"]\n",
    "    piano_roll = np.zeros((3, num_notes, duration_ticks))\n",
    "\n",
    "    for note in note_data:\n",
    "        # fixed duration for drum tracks since we only need the onsets\n",
    "        drum_track = note[\"channel\"] == 9\n",
    "        duration = 1 if drum_track else note[\"duration\"]\n",
    "\n",
    "        start = note[\"time\"]\n",
    "        end = min(start + duration, duration_ticks)\n",
    "        if end - start <= 0:\n",
    "            continue\n",
    "\n",
    "        pitch_class = note[\"note\"] % 12 if chroma else note[\"note\"]\n",
    "\n",
    "        velocity = note[\"velocity\"]\n",
    "        piano_roll_channel = 2 if drum_track and separate_drums else 0\n",
    "        piano_roll[piano_roll_channel, pitch_class, start:end] = velocity\n",
    "        if not instrument_overtones:\n",
    "            piano_roll[1, pitch_class, start:end] = velocity\n",
    "\n",
    "        if drum_track and not separate_drums:\n",
    "            piano_roll[0, pitch_class, start:end] = velocity\n",
    "\n",
    "        # Add overtones\n",
    "        if instrument_overtones and not drum_track:\n",
    "            program = note[\"program\"]\n",
    "            harmonics, intensities = instrument_overtone_intensities(program)\n",
    "            pitch = midi_to_hz(note[\"note\"])\n",
    "            max_intensity = intensities[0]\n",
    "            for harmonic, intensity in zip(harmonics, intensities):\n",
    "                overtone_pitch = pitch * harmonic\n",
    "                overtone_midi = hz_to_midi(overtone_pitch)\n",
    "                overtone_pitch_class = overtone_midi % 12 if chroma else overtone_midi\n",
    "                overtone_pitch_class = int(np.round(overtone_pitch_class))\n",
    "                if overtone_pitch_class <= 127:\n",
    "                    decay = np.linspace(1.0, 0.0, end - start) * intensity / max_intensity\n",
    "                    piano_roll[1, overtone_pitch_class, start:end] = velocity * intensity * decay\n",
    "\n",
    "    # Downsample to target_ticks_per_beat ticks per beat using max pooling\n",
    "    if ticks_per_beat > target_ticks_per_beat:\n",
    "        pool_size = ticks_per_beat // target_ticks_per_beat\n",
    "        try:\n",
    "            piano_roll = F.max_pool1d(torch.tensor(piano_roll), pool_size, stride=pool_size).numpy()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(piano_roll.shape)\n",
    "            return None\n",
    "    \n",
    "\n",
    "    return piano_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novelty_peak_pick_gsu(novelty_function: torch.Tensor, window_size: int, threshold_window_left: int, threshold_window_right: int, threshold: float = 0.37) -> torch.Tensor:\n",
    "    if novelty_function.shape[-1] < window_size:\n",
    "        candidate_idx = novelty_function.argmax()\n",
    "        return candidate_idx.unsqueeze(0) if novelty_function[candidate_idx] - novelty_function.mean() > threshold else torch.tensor([], dtype=torch.long, requires_grad=False, device=novelty_function.device)\n",
    "\n",
    "    window_half = window_size // 2\n",
    "\n",
    "    novelty_function = torch.cat((torch.zeros(*novelty_function.shape[:-1], window_half, device=novelty_function.device), novelty_function, torch.zeros(*novelty_function.shape[:-1], window_half, device=novelty_function.device)))\n",
    "\n",
    "    windows = novelty_function.unfold(-1, window_size, 1)\n",
    "    window_argmax = windows.argmax(dim=1)\n",
    "    \n",
    "    indices = torch.argwhere(window_argmax == window_half)[:, 0]\n",
    "    candidates = novelty_function[indices + window_half]\n",
    "\n",
    "    novelty_function = novelty_function[window_half:-window_half]\n",
    "\n",
    "    if candidates.shape[-1] == 0:\n",
    "        return torch.tensor([], dtype=torch.long, requires_grad=False, device=novelty_function.device)\n",
    "\n",
    "    starts = torch.maximum(indices - threshold_window_left, torch.tensor(0))\n",
    "    ends = torch.minimum(indices + threshold_window_right + 1, torch.tensor(novelty_function.shape[-1]))\n",
    "\n",
    "    means = torch.tensor([torch.mean(novelty_function[start:end]) for start, end in zip(starts, ends)], device=candidates.device)\n",
    "    candidates = candidates - means\n",
    "\n",
    "    return indices[candidates > threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prec_recall(input, target):\n",
    "    tp_count = ((input > 0) & (target == 1)).sum().item()\n",
    "    fp_count = ((input > 0) & (target == 0)).sum().item()\n",
    "    tn_count = ((input <= 0) & (target == 0)).sum().item()\n",
    "    fn_count = ((input <= 0) & (target == 1)).sum().item()\n",
    "\n",
    "    accuracy = (tp_count + tn_count) / (tp_count + tn_count + fp_count + fn_count) if tp_count + tn_count + fp_count + fn_count > 0 else 0\n",
    "    precision = tp_count / (tp_count + fp_count) if tp_count + fp_count > 0 else 0\n",
    "    recall = tp_count / (tp_count + fn_count) if tp_count + fn_count > 0 else 0\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def compute_metrics(input, target):\n",
    "    results = {}\n",
    "    for i in range(input.size(-1)):\n",
    "        acc, prec, recall = acc_prec_recall(input[..., i], target[..., i])\n",
    "        results[\"accuracy_\" + str(i)] = acc\n",
    "        results[\"precision_\" + str(i)] = prec\n",
    "        results[\"recall_\" + str(i)] = recall\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def prec_recall(input: List[bool], target: List[bool]):\n",
    "    tp = sum([1 for i, j in zip(input, target) if i and j])\n",
    "    fp = sum([1 for i, j in zip(input, target) if i and not j])\n",
    "    tn = sum([1 for i, j in zip(input, target) if not i and not j])\n",
    "    fn = sum([1 for i, j in zip(input, target) if not i and j])\n",
    "\n",
    "    prec = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "\n",
    "    return prec, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN boundary classifier\n",
    "class BoundaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        weights = torchvision.models.MobileNet_V3_Small_Weights.DEFAULT\n",
    "        backbone = torchvision.models.mobilenet_v3_small(weights=weights)\n",
    "        backbone.classifier[-1] = nn.Sequential(\n",
    "            nn.Linear(backbone.classifier[-1].in_features, NUM_TARGETS),\n",
    "        )\n",
    "        for layer in backbone.classifier:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight.data)\n",
    "        self.backbone = backbone\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaggedBoundaryClassifier(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.stack([model(x)[..., 0] for model in self.models], dim=0).mean(dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "\n",
    "# num_targets = [5, 1, 1, 1, 1]\n",
    "num_targets = [1, 1, 1, 1]\n",
    "model_paths = [\n",
    "    # Path('../models/pretrain_True_mn_overtones_True_normalized_True_separate_drums_True_targets_5_epoch_4 - best.pt'),\n",
    "    Path('../models/pretrain_False_mn_overtones_True_normalized_True_separate_drums_True_targets_1_epoch_5 - best.pt'),\n",
    "    Path('../models/pretrain_True_mn_overtones_False_normalized_True_separate_drums_False_targets_1_epoch_4 - best.pt'),\n",
    "    Path('../models/pretrain_True_mn_overtones_False_normalized_True_separate_drums_True_targets_1_epoch_2 - best.pt'),\n",
    "    Path('../models/pretrain_True_mn_overtones_True_normalized_True_separate_drums_True_targets_1_epoch_8 - best.pt')\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_path, num_targets in zip(model_paths, num_targets):\n",
    "    model = BoundaryClassifier(num_targets).to(device)\n",
    "    if model_path.exists():\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "    model = model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "model = BaggedBoundaryClassifier(models).to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BATCH_SIZE = 128\n",
    "CLASSIFICATION_THRESHOLD = 0.5\n",
    "padding = WINDOW_HALF_TICKS\n",
    "\n",
    "measure_qns_all = json.load(open(\"../data/measures_qn.json\"))\n",
    "good_files = json.load(open(\"../data/good_files_3_7_2025.json\"))\n",
    "test_files = {key: good_files[key] for key in good_files if key.endswith(\"test\")}\n",
    "\n",
    "evaluation_results = {}\n",
    "\n",
    "targets = {}\n",
    "results = {}\n",
    "with torch.no_grad():\n",
    "    for key in test_files:\n",
    "        print(f\"Processing files: {key}\")\n",
    "        evaluation_results[key] = []\n",
    "        targets[key] = []\n",
    "        results[key] = []\n",
    "\n",
    "        for test_example in (pbar := tqdm(test_files[key], desc=\"Loading test examples\")):\n",
    "            measure_qns = measure_qns_all[test_example]\n",
    "            midi_path = lakh_midi_dir / Path(f\"{test_example[0]}\") / Path(test_example + \".mid\")\n",
    "\n",
    "            # MIDI\n",
    "            try:\n",
    "                track_data, markers_ticks, ticks_per_beat = parse_midi(midi_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading MIDI file: {midi_path}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            # Annotation\n",
    "            if ticks_per_beat > TARGET_TICKS_PER_BEAT:\n",
    "                downsample_factor = ticks_per_beat // TARGET_TICKS_PER_BEAT\n",
    "                markers_ticks = [marker // downsample_factor for marker in markers_ticks]\n",
    "                measure_ticks = [int(round(qn * TARGET_TICKS_PER_BEAT)) for qn in measure_qns]\n",
    "            else:\n",
    "                print(f\"Skipping {test_example} due to downsample factor\")\n",
    "                continue\n",
    "\n",
    "            piano_rolls = []\n",
    "            # drum_piano_roll = None  # Separate channel\n",
    "            for track_name, note_data in track_data.items():\n",
    "                piano_roll = create_piano_roll(\n",
    "                    note_data,\n",
    "                    ticks_per_beat,\n",
    "                    chroma=False,\n",
    "                    target_ticks_per_beat=TARGET_TICKS_PER_BEAT,\n",
    "                    instrument_overtones=INSTRUMENT_OVERTONES,\n",
    "                    separate_drums=SEPARATE_DRUMS\n",
    "                )\n",
    "                # Some tracks are empty\n",
    "                if piano_roll is None:\n",
    "                    continue\n",
    "                piano_rolls.append(piano_roll)\n",
    "\n",
    "            if len(piano_rolls) == 0:\n",
    "                print(f\"Skipping {test_example} due to empty piano rolls\")\n",
    "                continue\n",
    "\n",
    "            actual_length = max(piano_roll.shape[-1] for piano_roll in piano_rolls)\n",
    "            for i, piano_roll in enumerate(piano_rolls):\n",
    "                piano_rolls[i] = torch.nn.functional.pad(torch.tensor(piano_roll),\n",
    "                                                         (0, actual_length - piano_roll.shape[-1]))\n",
    "\n",
    "            piano_roll = torch.stack(piano_rolls)\n",
    "            # Merge channels\n",
    "            piano_roll = piano_roll.sum(dim=0).clamp(0, 127).float().to(device)\n",
    "\n",
    "            # Compute first and last nonzero columns of the first channel (first and last onset, respectively)\n",
    "            batch_mask = piano_roll[0]  # Select the first batch\n",
    "\n",
    "            # Find nonzero column indices\n",
    "            nonzero_indices = batch_mask.nonzero(as_tuple=True)\n",
    "            if nonzero_indices[1].numel() > 0:\n",
    "                first_nonzero_column = nonzero_indices[1].min().item()\n",
    "                last_nonzero_column = nonzero_indices[1].max().item()\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            markers_ticks = torch.tensor(markers_ticks, device=device, dtype=torch.float32)\n",
    "            measure_ticks = torch.tensor(measure_ticks, device=device, dtype=torch.float32)\n",
    "            \n",
    "            markers_ticks = markers_ticks[markers_ticks > first_nonzero_column]\n",
    "            markers_ticks = markers_ticks[markers_ticks < last_nonzero_column]\n",
    "            measure_ticks = measure_ticks[measure_ticks > first_nonzero_column]\n",
    "            measure_ticks = measure_ticks[measure_ticks < last_nonzero_column]\n",
    "\n",
    "            # Add first and last nonzero column to the segment boundaries\n",
    "            markers_ticks = torch.cat([\n",
    "                torch.tensor([first_nonzero_column], dtype=torch.float32, device=piano_roll.device),\n",
    "                markers_ticks,\n",
    "                torch.tensor([last_nonzero_column], dtype=torch.float32, device=piano_roll.device)\n",
    "            ])\n",
    "            measure_tickss = torch.cat([\n",
    "                torch.tensor([first_nonzero_column], dtype=torch.float32, device=piano_roll.device),\n",
    "                measure_ticks,\n",
    "                torch.tensor([last_nonzero_column], dtype=torch.float32, device=piano_roll.device)\n",
    "            ])\n",
    "\n",
    "            # Crop piano roll to the first and last onset\n",
    "            piano_roll = piano_roll[..., first_nonzero_column:last_nonzero_column + 1]\n",
    "            # Adjust segment boundaries to the cropped piano roll\n",
    "            markers_ticks -= first_nonzero_column\n",
    "            measure_ticks -= first_nonzero_column\n",
    "\n",
    "            if PAD_PIANO_ROLL:\n",
    "                piano_roll = F.pad(piano_roll, (padding, padding), mode='constant', value=0)\n",
    "                markers_ticks += padding\n",
    "                measure_ticks += padding\n",
    "\n",
    "            batches = []\n",
    "            curr_targets = []\n",
    "            tik = time.time()\n",
    "            for measure_tick in measure_ticks:\n",
    "                start = measure_tick - WINDOW_HALF_TICKS\n",
    "                end = measure_tick + WINDOW_HALF_TICKS\n",
    "                \n",
    "                if not PAD_PIANO_ROLL and (start <= 0 or end >= piano_roll.shape[-1]):\n",
    "                    continue\n",
    "\n",
    "                curr_targets.append(True if measure_tick in markers_ticks else False)\n",
    "\n",
    "                patch = piano_roll[..., start:end].float().to(device)\n",
    "                if PATCH_NORMALIZE:\n",
    "                    patch = patch / patch.max()\n",
    "\n",
    "                batches.append(patch)\n",
    "\n",
    "            if len(batches) == 0:\n",
    "                continue\n",
    "\n",
    "            batches = torch.stack(batches)\n",
    "\n",
    "            tok = time.time()\n",
    "            patch_preparation_time = tok - tik\n",
    "\n",
    "            measure_predictions = []\n",
    "            tik = time.time()\n",
    "            for i in range(math.ceil(batches.shape[0] / MAX_BATCH_SIZE)):\n",
    "                torch.mps.empty_cache()\n",
    "                result = model(batches[i * MAX_BATCH_SIZE:i * MAX_BATCH_SIZE + MAX_BATCH_SIZE])\n",
    "                measure_prediction = F.sigmoid(result)\n",
    "                measure_predictions += measure_prediction.tolist()\n",
    "            tok = time.time()\n",
    "            prediction_time = tok - tik\n",
    "\n",
    "            tik = time.time()\n",
    "            peak_indices = novelty_peak_pick_gsu(torch.tensor(measure_predictions), 8, 8, 4)\n",
    "            measure_predictions_peak_pick = torch.tensor([False for _ in range(len(curr_targets))])\n",
    "            measure_predictions_peak_pick[peak_indices] = True\n",
    "            tok = time.time()\n",
    "            peak_pick_time = tok - tik\n",
    "\n",
    "            results[key] += [prediction > CLASSIFICATION_THRESHOLD for prediction in measure_predictions]\n",
    "            targets[key] += curr_targets\n",
    "\n",
    "            prec_threshold, recall_threshold = prec_recall([prediction > CLASSIFICATION_THRESHOLD for prediction in measure_predictions], curr_targets)\n",
    "            f1_threshold = 2 * prec_threshold * recall_threshold / (prec_threshold + recall_threshold) if prec_threshold + recall_threshold > 0 else 0\n",
    "\n",
    "            prec_peak_pick, recall_peak_pick = prec_recall(measure_predictions_peak_pick, curr_targets)\n",
    "            f1_peak_pick = 2 * prec_peak_pick * recall_peak_pick / (prec_peak_pick + recall_peak_pick) if prec_peak_pick + recall_peak_pick > 0 else 0\n",
    "\n",
    "            evaluation_results[key].append({\n",
    "                test_example: {\n",
    "                    \"f1_threshold\": f1_threshold,\n",
    "                    \"f1_peak_pick\": f1_peak_pick,\n",
    "                    \"prec_threshold\": prec_threshold,\n",
    "                    \"recall_threshold\": recall_threshold,\n",
    "                    \"prec_peak_pick\": prec_peak_pick,\n",
    "                    \"recall_peak_pick\": recall_peak_pick,\n",
    "                    \"patch_preparation_time_ms\": patch_preparation_time * 1000,\n",
    "                    \"prediction_time_ms\": prediction_time * 1000,\n",
    "                    \"peak_pick_time_ms\": peak_pick_time * 1000\n",
    "                }\n",
    "            })\n",
    "            f1_threshold_mean = np.mean([example_result[\"f1_threshold\"] for x in evaluation_results[key] for example_result in x.values()])\n",
    "            f1_peak_pick_mean = np.mean([example_result[\"f1_peak_pick\"] for x in evaluation_results[key] for example_result in x.values()])\n",
    "\n",
    "            pbar.set_postfix(f1_thresholding_mean=f1_threshold_mean, f1_peak_pick_mean=f1_peak_pick_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_tubb, recall_tubb = prec_recall(results[\"tubb_test\"], targets[\"tubb_test\"])\n",
    "f1_tubb = 2 * prec_tubb * recall_tubb / (prec_tubb + recall_tubb) if prec_tubb + recall_tubb > 0 else 0\n",
    "\n",
    "prec_non_tubb, recall_non_tubb = prec_recall(results[\"non_tubb_test\"], targets[\"non_tubb_test\"])\n",
    "f1_non_tubb = 2 * prec_non_tubb * recall_non_tubb / (prec_non_tubb + recall_non_tubb) if prec_non_tubb + recall_non_tubb > 0 else 0\n",
    "\n",
    "prec_all, recall_all = prec_recall([result for key in results for result in results[key]], [target for key in targets for target in targets[key]])\n",
    "f1_all = 2 * prec_all * recall_all / (prec_all + recall_all) if prec_all + recall_all > 0 else 0\n",
    "\n",
    "print(f\"Precision Tubb: {prec_tubb}\")\n",
    "print(f\"Recall Tubb: {recall_tubb}\")\n",
    "print(f\"F1 Tubb: {f1_tubb}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Precision Non-Tubb: {prec_non_tubb}\")\n",
    "print(f\"Recall Non-Tubb: {recall_non_tubb}\")\n",
    "print(f\"F1 Non-Tubb: {f1_non_tubb}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Precision All: {prec_all}\")\n",
    "print(f\"Recall All: {recall_all}\")\n",
    "print(f\"F1 All: {f1_all}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tubb_test_f1_mean = np.mean([example_result[\"f1_threshold\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "tubb_test_prec_mean = np.mean([example_result[\"prec_threshold\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "tubb_test_recall_mean = np.mean([example_result[\"recall_threshold\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "\n",
    "non_tubb_test_f1_mean = np.mean([example_result[\"f1_threshold\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "non_tubb_test_prec_mean = np.mean([example_result[\"prec_threshold\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "non_tubb_test_recall_mean = np.mean([example_result[\"recall_threshold\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "\n",
    "print(f\"TUBB test set F1 mean: {tubb_test_f1_mean}\")\n",
    "print(f\"TUBB test set Precision mean: {tubb_test_prec_mean}\")\n",
    "print(f\"TUBB test set Recall mean: {tubb_test_recall_mean}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Non-TUBB test set F1 mean: {non_tubb_test_f1_mean}\")\n",
    "print(f\"Non-TUBB test set Precision mean: {non_tubb_test_prec_mean}\")\n",
    "print(f\"Non-TUBB test set Recall mean: {non_tubb_test_recall_mean}\")\n",
    "\n",
    "print()\n",
    "\n",
    "tubb_test_f1_mean = np.mean([example_result[\"f1_peak_pick\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "tubb_test_prec_mean = np.mean([example_result[\"prec_peak_pick\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "tubb_test_recall_mean = np.mean([example_result[\"recall_peak_pick\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])\n",
    "\n",
    "non_tubb_test_f1_mean = np.mean([example_result[\"f1_peak_pick\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "non_tubb_test_prec_mean = np.mean([example_result[\"prec_peak_pick\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "non_tubb_test_recall_mean = np.mean([example_result[\"recall_peak_pick\"] for x in evaluation_results[\"non_tubb_test\"] for example_result in x.values()])\n",
    "\n",
    "print(f\"TUBB test set F1 mean: {tubb_test_f1_mean}\")\n",
    "print(f\"TUBB test set Precision mean: {tubb_test_prec_mean}\")\n",
    "print(f\"TUBB test set Recall mean: {tubb_test_recall_mean}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Non-TUBB test set F1 mean: {non_tubb_test_f1_mean}\")\n",
    "print(f\"Non-TUBB test set Precision mean: {non_tubb_test_prec_mean}\")\n",
    "print(f\"Non-TUBB test set Recall mean: {non_tubb_test_recall_mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"../results\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# export evaluation results to json\n",
    "json.dump(evaluation_results, open(f\"../results/evaluation_results_{int(time.time())}.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([example_result[\"patch_preparation_time_ms\"] for x in evaluation_results[\"tubb_test\"] for example_result in x.values()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
